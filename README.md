# 한국 뉴스 rss 수집기
한국 언론사의 rss 주소를 수집한다.

# 목적
한국 언론사의 rss 주소를 수집한다.

# 사용법
## 사전 준비
* 테스트 환경: python3.10
* 필수 패키지: `requests`, `bs4`, `feedparser`, `tqdm`, `lxml`

## 데이터
* name: str = RSS 대표 주소 이름
* url: str = 홈페이지 주소
* status: str = 웹페이지 운영 현황
  * `parsed`: rss 정보 추출됨
  * `ready`: 사이트 주소만 수집됨(rss 정보 분석 전)
  * `unable`: 접속 불가
  * `disable`: 수집 금지
* rss: list[str, dict[str, str]] = RSS 종류와 주소 이름
* site: dict[str, dict[str, str]] = 웹사이트 접속시 상태 코드와 내용
* extra: dict[str, object] = 기타 정보 저장



# 제작 중 어려움을 겪은 부분
* 헤더의 인코딩과 실제 텍스트 인코딩이 달라서 오류가 발생
  * 실제 텍스트 인코딩으로 적용되도록 구성
* 웹사이트 주소의 보안이 올바르지 않은 문제 발생
  * ~~해당 웹사이트 접속시 낮은 보안에도 작동되도록 수정~~
  * ~~`TLS1.0`에도 접속 가능하도록 수정~~
    * 그정도로 보안이 낮은 사이트라면 적절한 정보를 얻기 곤란하다고 판단되어 보류


# Version 1.0 제작하면서 생각한 점
* 웹페이지 크롤링은 하나의 웹사이트일 경우가 많아서 다중 클라이언트가 필수로 보인다.
* 사이트 중복 요청을 최소화 하기 위해 cache를 dict로 구성하였다.
* 사이트 정보를 json 안에 모두 저장한다.


# Version 2.0 제작시 고려할만한 점
* Redis로 cache를 사용한다.
* 사이트 정보를 db에 저장한다.
* html 정보를 zip에 저장한다.
* cli에서 사용하기 편하도록 argparse를 적용한다.
* 